---
layout: post
title: 'Showing up! #6'
description: "rough notes of what things I did today"
category: upstream-contribution
tags: [kubernetes]
comments: false
---

May 06, 2021

Today was a so so day. I would say, the last some hours were hard, other than that it was wonderful in the morning. I did more than usual productive stuff during the time. 

**(see, I myself am confused, that's why it was hard. Just too much overthinking happening. üòÖ).**

Well, I didn't feel like writing today. But then times like these become the culprit behind me breaking a good going streak. So, decided to just quickly put down some lines.

---

***So, updates from today:***

I continued with the **Red Hat OpenShift Administration I (DO280)** virtual instructor led training (VILT).

- Learnt about the OpenShift **Pod Scheduler Algorithm** today. It's a three step process:

     1.  **Filtering nodes**:

          > - The scheduler filters the list of running nodes by evaluating each node against a set of predicates, such as the availability of host ports, or whether a pod can be scheduled to a node experiencing either disk or memory pressure.
          >
          > - Additionally, a pod can define a `node selector` that matches the `labels` in the cluster nodes. Nodes whose labels do not match are not eligible.
          > 
          > - A pod can also define resource requests for compute resources such as CPU, memory, and storage. Nodes that have insufficient free computer resources are not eligible.
          > 
          > - Another filtering check evaluates if the list of nodes have any `taints`, and if so whether the pod has an associated `toleration` that can accept the taint. If a pod cannot accept the taint of a node, then the node is not eligible. By default, control plane nodes include the taint `node-role.kubernetes.io/master:NoSchedule`. A pod that does not have a matching toleration for this taint will not be scheduled to a control plane node.
          >
          > The end result of the filtering step is typically a shorter list of node candidates that are eligible to run the pod. In some cases, none of the nodes are filtered out, which means the pod could run on any of the nodes.
          >
          > In other cases, all of the nodes are filtered out, which means the pod cannot be scheduled until a node with the desired prerequisites becomes available.

     2.  **Prioritizing the filtered list of nodes**:

          > - The list of candidate nodes is evaluated using multiple priority criteria that add up to a weighted score. Nodes with higher values are better candidates to run the pod.
          > 
          > - Among the criteria are `affinity` and `anti-affinity` rules. 
          >     - Nodes with higher affinity for the pod have a higher score. 
          >     - Nodes with higher anti-affinity have a lower score.
          >     
          >  - A common use for `affinity` rules is to schedule related pods to be close to each other, for performance reasons. An example is to use the same network backbone for pods that synchronize with each other.
          >  
          >  - A common use for `anti-affinity` rules is to schedule related pods that are not too close to each other, for high availability. An example is to avoid scheduling all pods from the same application to the same node.     

          (`anti-affinity`, `affinity` rules with `node-selectors` ~ I've used this combination in the previous jobs. Good to have proper definition to what they do now.)

     3.   **Selecting the best fit node.**:

          > The candidate list is sorted based on these scores, and the node with the highest score is selected to host the pod. If multiple nodes have the same high score, then one is selected in a `round-robin` fashion.
     
     
- Also learnt about the concept of `ResourceQuotas` & `LimitRanges` for limiting resource usage by an application.

- And finally, most of the day was doing labs around managing an OpenShift cluster from the web console. Never thought, I would be stuck at labs asking to do stuffs from a UI. It is so easy on the terminal. Anyways, yes, I'm stuck on literally the last & only one step of a grading lab. And that's why the frustration in the last hours (& so all those funny emotions, crying & feeling like I'm the only poor & alone thing in this whole world üòÜ ü§∑‚Äç‚ôÄÔ∏è). Will ask the instructor in tomorrow's class for help.

---

***updates from the upstream kubernetes contributions:***

- In the morning, fixed review comments on the [ (add 'list_ingressroute_for_all_namespaces' method #1454)](https://github.com/kubernetes-client/python/pull/1454). It's merged now.

That's all from today. Tata everyone. o/

















